{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np","metadata":{"id":"buUKSjKqgwM4","execution":{"iopub.status.busy":"2023-11-11T15:00:33.628079Z","iopub.execute_input":"2023-11-11T15:00:33.628676Z","iopub.status.idle":"2023-11-11T15:00:45.807140Z","shell.execute_reply.started":"2023-11-11T15:00:33.628647Z","shell.execute_reply":"2023-11-11T15:00:45.806340Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install googledrivedownloader","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:02:21.318807Z","iopub.execute_input":"2023-11-11T15:02:21.319687Z","iopub.status.idle":"2023-11-11T15:02:34.161914Z","shell.execute_reply.started":"2023-11-11T15:02:21.319652Z","shell.execute_reply":"2023-11-11T15:02:34.160808Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting googledrivedownloader\n  Downloading googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\nInstalling collected packages: googledrivedownloader\nSuccessfully installed googledrivedownloader-0.4\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"Dataloading for Omniglot.\"\"\"\nimport os\nimport glob\n\nimport google_drive_downloader as gdd\nimport imageio\nimport numpy as np\nimport torch\nfrom torch.utils.data import dataset, sampler, dataloader\n\nNUM_TRAIN_CLASSES = 1100\nNUM_VAL_CLASSES = 100\nNUM_TEST_CLASSES = 423\nNUM_SAMPLES_PER_CLASS = 20\n\n\ndef load_image(file_path):\n    \"\"\"Loads and transforms an Omniglot image.\n\n    Args:\n        file_path (str): file path of image\n\n    Returns:\n        a Tensor containing image data\n            shape (1, 28, 28)\n    \"\"\"\n    x = imageio.imread(file_path)\n    x = torch.tensor(x, dtype=torch.float32).reshape([1, 28, 28]) # (channel, width, height)\n    x = x / 255.0\n    return 1 - x\n\n\nclass OmniglotDataset(dataset.Dataset):\n    \"\"\"Omniglot dataset for meta-learning.\n\n    Each element of the dataset is a task. A task is specified with a key,\n    which is a tuple of class indices (no particular order). The corresponding\n    value is the instantiated task, which consists of sampled (image, label)\n    pairs.\n    \"\"\"\n\n    _BASE_PATH = './omniglot_resized'\n    _GDD_FILE_ID = '1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI'\n\n    def __init__(self, num_support, num_query):\n        \"\"\"Inits OmniglotDataset.\n\n        Args:\n            num_support (int): number of support examples per class\n            num_query (int): number of query examples per class\n        \"\"\"\n        super().__init__()\n\n\n        # if necessary, download the Omniglot dataset\n        if not os.path.isdir(self._BASE_PATH):\n            gdd.GoogleDriveDownloader.download_file_from_google_drive(\n                file_id=self._GDD_FILE_ID,\n                dest_path=f'{self._BASE_PATH}.zip',\n                unzip=True\n            )\n\n        # get all character folders\n        self._character_folders = glob.glob(\n            os.path.join(self._BASE_PATH, '*/*/'))\n        assert len(self._character_folders) == (\n            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n        )\n\n        # shuffle characters\n        np.random.default_rng(0).shuffle(self._character_folders)\n\n        # check problem arguments\n        assert num_support + num_query <= NUM_SAMPLES_PER_CLASS\n        self._num_support = num_support\n        self._num_query = num_query\n\n    def __getitem__(self, class_idxs):\n        \"\"\"Constructs a task.\n\n        Data for each class is sampled uniformly at random without replacement.\n        The ordering of the labels corresponds to that of class_idxs.\n\n        Args:\n            class_idxs (tuple[int]): class indices that comprise the task\n\n        Returns:\n            images_support (Tensor): task support images\n                shape (num_way * num_support, channels, height, width)\n            labels_support (Tensor): task support labels\n                shape (num_way * num_support,)\n            images_query (Tensor): task query images\n                shape (num_way * num_query, channels, height, width)\n            labels_query (Tensor): task query labels\n                shape (num_way * num_query,)\n        \"\"\"\n        images_support, images_query = [], []\n        labels_support, labels_query = [], []\n\n        for label, class_idx in enumerate(class_idxs):\n            # get a class's examples and sample from them\n            all_file_paths = glob.glob(\n                os.path.join(self._character_folders[class_idx], '*.png')\n            )\n            sampled_file_paths = np.random.default_rng().choice(\n                all_file_paths,\n                size=self._num_support + self._num_query,\n                replace=False\n            )\n            images = [load_image(file_path) for file_path in sampled_file_paths]\n\n            # split sampled examples into support and query\n            images_support.extend(images[:self._num_support])\n            images_query.extend(images[self._num_support:])\n            labels_support.extend([label] * self._num_support)\n            labels_query.extend([label] * self._num_query)\n\n        # aggregate into tensors\n        images_support = torch.stack(images_support)  # shape (N*S, C, H, W)\n        labels_support = torch.tensor(labels_support)  # shape (N*S)\n        images_query = torch.stack(images_query)\n        labels_query = torch.tensor(labels_query)\n\n        return images_support, labels_support, images_query, labels_query\n\n\nclass OmniglotSampler(sampler.Sampler):\n    \"\"\"Samples task specification keys for an OmniglotDataset.\"\"\"\n\n    def __init__(self, split_idxs, num_way, num_tasks):\n        \"\"\"Inits OmniglotSampler.\n\n        Args:\n            split_idxs (range): indices that comprise the\n                training/validation/test split\n            num_way (int): number of classes per task\n            num_tasks (int): number of tasks to sample\n        \"\"\"\n        super().__init__(None)\n        self._split_idxs = split_idxs\n        self._num_way = num_way\n        self._num_tasks = num_tasks\n\n    def __iter__(self):\n        return (\n            np.random.default_rng().choice(\n                self._split_idxs,\n                size=self._num_way,\n                replace=False\n            ) for _ in range(self._num_tasks)\n        )\n\n    def __len__(self):\n        return self._num_tasks\n\n\ndef identity(x):\n    return x\n\n\ndef get_omniglot_dataloader(\n        split,\n        batch_size,\n        num_way,\n        num_support,\n        num_query,\n        num_tasks_per_epoch\n):\n    \"\"\"Returns a dataloader.DataLoader for Omniglot.\n\n    Args:\n        split (str): one of 'train', 'val', 'test'\n        batch_size (int): number of tasks per batch\n        num_way (int): number of classes per task\n        num_support (int): number of support examples per class\n        num_query (int): number of query examples per class\n        num_tasks_per_epoch (int): number of tasks before DataLoader is\n            exhausted\n    \"\"\"\n\n    if split == 'train':\n        split_idxs = range(NUM_TRAIN_CLASSES)\n    elif split == 'val':\n        split_idxs = range(\n            NUM_TRAIN_CLASSES,\n            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES\n        )\n    elif split == 'test':\n        split_idxs = range(\n            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES,\n            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n        )\n    else:\n        raise ValueError\n\n    return dataloader.DataLoader(\n        dataset=OmniglotDataset(num_support, num_query),\n        batch_size=batch_size,\n        sampler=OmniglotSampler(split_idxs, num_way, num_tasks_per_epoch),\n        num_workers=2,\n        collate_fn=identity,\n        pin_memory=torch.cuda.is_available(),\n        drop_last=True\n    )","metadata":{"id":"26MyoFL3u7o_","execution":{"iopub.status.busy":"2023-11-11T15:02:40.622527Z","iopub.execute_input":"2023-11-11T15:02:40.623128Z","iopub.status.idle":"2023-11-11T15:02:40.646002Z","shell.execute_reply.started":"2023-11-11T15:02:40.623078Z","shell.execute_reply":"2023-11-11T15:02:40.645102Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loader = get_omniglot_dataloader(\"train\", 10, 3, 5, 1, 1000)","metadata":{"id":"AiP0wfyfu-Ul","execution":{"iopub.status.busy":"2023-11-11T15:02:40.998569Z","iopub.execute_input":"2023-11-11T15:02:40.998953Z","iopub.status.idle":"2023-11-11T15:03:14.972947Z","shell.execute_reply.started":"2023-11-11T15:02:40.998923Z","shell.execute_reply":"2023-11-11T15:03:14.972026Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading 1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI into ./omniglot_resized.zip... Done.\nUnzipping...Done.\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_loader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-c28XQ9vq5a","outputId":"564c56af-e154-4827-a0dc-d05cfc3434f1","execution":{"iopub.status.busy":"2023-11-11T15:03:14.974521Z","iopub.execute_input":"2023-11-11T15:03:14.974800Z","iopub.status.idle":"2023-11-11T15:03:14.982063Z","shell.execute_reply.started":"2023-11-11T15:03:14.974776Z","shell.execute_reply":"2023-11-11T15:03:14.981165Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}]},{"cell_type":"code","source":"for data in train_loader:\n  print(data[0][0].shape)\n  break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lrTGfrKTvP-U","outputId":"40e5e734-c2dc-4d68-92e8-12e423c1e231","execution":{"iopub.status.busy":"2023-11-11T15:03:14.983324Z","iopub.execute_input":"2023-11-11T15:03:14.983909Z","iopub.status.idle":"2023-11-11T15:03:15.430746Z","shell.execute_reply.started":"2023-11-11T15:03:14.983876Z","shell.execute_reply":"2023-11-11T15:03:15.429637Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([15, 1, 28, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"UOod9HSfvP4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Utilities for scoring the model.\"\"\"\nimport torch\n\n\ndef score(logits, labels):\n    \"\"\"Returns the mean accuracy of a model's predictions on a set of examples.\n\n    Args:\n        logits (torch.Tensor): model predicted logits\n            shape (examples, classes)\n        labels (torch.Tensor): classification labels from 0 to num_classes - 1\n            shape (examples,)\n    \"\"\"\n\n    assert logits.dim() == 2\n    assert labels.dim() == 1\n    assert logits.shape[0] == labels.shape[0]\n    y = torch.argmax(logits, dim=-1) == labels\n    y = y.type(torch.float)\n    return torch.mean(y).item()","metadata":{"id":"Oakiic6PvPxP","execution":{"iopub.status.busy":"2023-11-11T15:03:15.434076Z","iopub.execute_input":"2023-11-11T15:03:15.434808Z","iopub.status.idle":"2023-11-11T15:03:15.441616Z","shell.execute_reply.started":"2023-11-11T15:03:15.434774Z","shell.execute_reply":"2023-11-11T15:03:15.440562Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"Implementation of model-agnostic meta-learning for Omniglot.\"\"\"\n\nimport argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch import autograd  # pylint: disable=unused-import\nfrom torch.utils import tensorboard\n\n\nNUM_INPUT_CHANNELS = 1\nNUM_HIDDEN_CHANNELS = 64\nKERNEL_SIZE = 3\nNUM_CONV_LAYERS = 4\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nSUMMARY_INTERVAL = 10\nSAVE_INTERVAL = 100\nLOG_INTERVAL = 10\nVAL_INTERVAL = LOG_INTERVAL * 5\nNUM_TEST_TASKS = 600\n\n\nclass MAML:\n    \"\"\"Trains and assesses a MAML.\"\"\"\n\n    def __init__(\n            self,\n            num_outputs,\n            num_inner_steps,\n            inner_lr,\n            learn_inner_lrs,\n            outer_lr,\n            log_dir\n    ):\n        \"\"\"Inits MAML.\n\n        The network consists of four convolutional blocks followed by a linear\n        head layer. Each convolutional block comprises a convolution layer, a\n        batch normalization layer, and ReLU activation.\n\n        Note that unlike conventional use, batch normalization is always done\n        with batch statistics, regardless of whether we are training or\n        evaluating. This technically makes meta-learning transductive, as\n        opposed to inductive.\n\n        Args:\n            num_outputs (int): dimensionality of output, i.e. number of classes\n                in a task\n            num_inner_steps (int): number of inner-loop optimization steps\n            inner_lr (float): learning rate for inner-loop optimization\n                If learn_inner_lrs=True, inner_lr serves as the initialization\n                of the learning rates.\n            learn_inner_lrs (bool): whether to learn the above\n            outer_lr (float): learning rate for outer-loop optimization\n            log_dir (str): path to logging directory\n        \"\"\"\n        meta_parameters = {}\n\n        # construct feature extractor\n        in_channels = NUM_INPUT_CHANNELS\n        for i in range(NUM_CONV_LAYERS):\n            meta_parameters[f'conv{i}'] = nn.init.xavier_uniform_(\n                torch.empty(\n                    NUM_HIDDEN_CHANNELS,\n                    in_channels,\n                    KERNEL_SIZE,\n                    KERNEL_SIZE,\n                    requires_grad=True,\n                    device=DEVICE\n                )\n            )\n            meta_parameters[f'b{i}'] = nn.init.zeros_(\n                torch.empty(\n                    NUM_HIDDEN_CHANNELS,\n                    requires_grad=True,\n                    device=DEVICE\n                )\n            )\n            in_channels = NUM_HIDDEN_CHANNELS\n\n        # construct linear head layer\n        meta_parameters[f'w{NUM_CONV_LAYERS}'] = nn.init.xavier_uniform_(\n            torch.empty(\n                num_outputs,\n                NUM_HIDDEN_CHANNELS,\n                requires_grad=True,\n                device=DEVICE\n            )\n        )\n        meta_parameters[f'b{NUM_CONV_LAYERS}'] = nn.init.zeros_(\n            torch.empty(\n                num_outputs,\n                requires_grad=True,\n                device=DEVICE\n            )\n        )\n\n        self._meta_parameters = meta_parameters\n        self._num_inner_steps = num_inner_steps\n        self._inner_lrs = {\n            k: torch.tensor(inner_lr, requires_grad=learn_inner_lrs)\n            for k in self._meta_parameters.keys()\n        }\n        self._outer_lr = outer_lr\n\n        self._optimizer = torch.optim.Adam(\n            list(self._meta_parameters.values()) +\n            list(self._inner_lrs.values()),\n            lr=self._outer_lr\n        )\n\n        self._log_dir = log_dir\n        os.makedirs(self._log_dir, exist_ok=True)\n\n        self._start_train_step = 0\n\n    def _forward(self, images, parameters):\n        \"\"\"Computes predicted classification logits.\n\n        Args:\n            images (Tensor): batch of Omniglot images\n                shape (num_images, channels, height, width)\n            parameters (dict[str, Tensor]): parameters to use for\n                the computation\n\n        Returns:\n            a Tensor consisting of a batch of logits\n                shape (num_images, classes)\n        \"\"\"\n        x = images\n        for i in range(NUM_CONV_LAYERS):\n            x = F.conv2d(\n                input=x,\n                weight=parameters[f'conv{i}'],\n                bias=parameters[f'b{i}'],\n                stride=1,\n                padding='same'\n            )\n            x = F.batch_norm(x, None, None, training=True)\n            x = F.relu(x)\n        x = torch.mean(x, dim=[2, 3])\n        return F.linear(\n            input=x,\n            weight=parameters[f'w{NUM_CONV_LAYERS}'],\n            bias=parameters[f'b{NUM_CONV_LAYERS}']\n        )\n\n    def _inner_loop(self, images, labels, train):   # pylint: disable=unused-argument\n        \"\"\"Computes the adapted network parameters via the MAML inner loop.\n\n        Args:\n            images (Tensor): task support set inputs\n                shape (num_images, channels, height, width)\n            labels (Tensor): task support set outputs\n                shape (num_images,)\n            train (bool): whether we are training or evaluating (not necessary?)\n\n        Returns:\n            parameters (dict[str, Tensor]): adapted network parameters\n            accuracies (list[float]): support set accuracy over the course of\n                the inner loop, length num_inner_steps + 1\n        \"\"\"\n        accuracies = []\n        parameters = {\n            k: torch.clone(v)\n            for k, v in self._meta_parameters.items()\n        }\n        # ********************************************************\n        # ******************* YOUR CODE HERE *********************\n        # ********************************************************\n        # TODO: finish implementing this method.\n        # This method computes the inner loop (adaptation) procedure for one\n        # task. It also scores the model along the way.\n        # Make sure to populate accuracies and update parameters.\n        # Use F.cross_entropy to compute classification losses.\n        # Use util.score to compute accuracies.\n\n        # here we are doing \\phi_i = \\theta - inner_lr * grad(\\theta, L, D_{tr})\n        for _ in range(self._num_inner_steps):\n            logits = self._forward(images, parameters)\n            loss = F.cross_entropy(logits, labels)\n\n            # create graph due to computing second order derivatives in MAML\n            gradients = autograd.grad(\n                loss, parameters.values(), create_graph=True)\n\n            # update parameters\n            for i in range(len(parameters.keys())):\n                k = list(parameters.keys())[i]\n                v = list(parameters.values())[i]\n                assert v.shape == gradients[i].shape, 'Not proper shape'\n\n                parameters[k] = v - self._inner_lrs[k] * gradients[i]\n\n            acc = score(logits, labels)\n            accuracies.append(acc)\n\n        final_logits = self._forward(images, parameters)\n        final_acc = score(final_logits, labels)\n        accuracies.append(final_acc)\n        # ********************************************************\n        # ******************* YOUR CODE HERE *********************\n        # ********************************************************\n        return parameters, accuracies\n\n    def _outer_step(self, task_batch, train):  # pylint: disable=unused-argument\n        \"\"\"Computes the MAML loss and metrics on a batch of tasks.\n\n        Args:\n            task_batch (tuple): batch of tasks from an Omniglot DataLoader\n            train (bool): whether we are training or evaluating\n\n        Returns:\n            outer_loss (Tensor): mean MAML loss over the batch, scalar\n            accuracies_support (ndarray): support set accuracy over the\n                course of the inner loop, averaged over the task batch\n                shape (num_inner_steps + 1,)\n            accuracy_query (float): query set accuracy of the adapted\n                parameters, averaged over the task batch\n        \"\"\"\n        outer_loss_batch = []\n        accuracies_support_batch = []\n        accuracy_query_batch = []\n        for task in task_batch:\n            images_support, labels_support, images_query, labels_query = task\n            images_support = images_support.to(DEVICE)\n            labels_support = labels_support.to(DEVICE)\n            images_query = images_query.to(DEVICE)\n            labels_query = labels_query.to(DEVICE)\n            # ********************************************************\n            # ******************* YOUR CODE HERE *********************\n            # ********************************************************\n            # TODO: finish implementing this method.\n            # For a given task, use the _inner_loop method to adapt, then\n            # compute the MAML loss and other metrics.\n            # Use F.cross_entropy to compute classification losses.\n            # Use util.score to compute accuracies.\n            # Make sure to populate outer_loss_batch, accuracies_support_batch,\n            # and accuracy_query_batch.\n\n            # computes \\phi_L\n            parameters, supp_accs = self._inner_loop(\n                images_support, labels_support, train)\n\n            # gets the loss w.r.t. \\phi_L\n            logits = self._forward(images_query, parameters)\n            loss = F.cross_entropy(logits, labels_query)\n            outer_loss_batch.append(loss)\n\n            accuracies_support_batch.append(supp_accs)\n            q_accs = score(logits, labels_query)\n            accuracy_query_batch.append(q_accs)\n\n            # ********************************************************\n            # ******************* YOUR CODE HERE *********************\n            # ********************************************************\n        outer_loss = torch.mean(torch.stack(outer_loss_batch))\n        accuracies_support = np.mean(\n            accuracies_support_batch,\n            axis=0\n        )\n\n        accuracy_query = np.mean(accuracy_query_batch)\n        return outer_loss, accuracies_support, accuracy_query\n\n    def train(self, dataloader_train, dataloader_val, writer):\n        \"\"\"Train the MAML.\n\n        Consumes dataloader_train to optimize MAML meta-parameters\n        while periodically validating on dataloader_val, logging metrics, and\n        saving checkpoints.\n\n        Args:\n            dataloader_train (DataLoader): loader for train tasks\n            dataloader_val (DataLoader): loader for validation tasks\n            writer (SummaryWriter): TensorBoard logger\n        \"\"\"\n        print(f'Starting training at iteration {self._start_train_step}.')\n\n        for i_step, task_batch in enumerate(\n                dataloader_train,\n                start=self._start_train_step\n        ):\n\n            self._optimizer.zero_grad()\n            outer_loss, accuracies_support, accuracy_query = (\n                self._outer_step(task_batch, train=True)\n            )\n\n            outer_loss.backward()\n            self._optimizer.step()\n\n            if i_step % LOG_INTERVAL == 0:\n                print(\n                    f'Iteration {i_step}: '\n                    f'loss: {outer_loss.item():.3f}, '\n                    f'pre-adaptation support accuracy: '\n                    f'{accuracies_support[0]:.3f}, '\n                    f'post-adaptation support accuracy: '\n                    f'{accuracies_support[-1]:.3f}, '\n                    f'post-adaptation query accuracy: '\n                    f'{accuracy_query:.3f}'\n                )\n                writer.add_scalar('loss/train', outer_loss.item(), i_step)\n                writer.add_scalar(\n                    'train_accuracy/pre_adapt_support',\n                    accuracies_support[0],\n                    i_step\n                )\n                writer.add_scalar(\n                    'train_accuracy/post_adapt_support',\n                    accuracies_support[-1],\n                    i_step\n                )\n                writer.add_scalar(\n                    'train_accuracy/post_adapt_query',\n                    accuracy_query,\n                    i_step\n                )\n\n            if i_step % VAL_INTERVAL == 0:\n                losses = []\n                accuracies_pre_adapt_support = []\n                accuracies_post_adapt_support = []\n                accuracies_post_adapt_query = []\n                for val_task_batch in dataloader_val:\n                    outer_loss, accuracies_support, accuracy_query = (\n                        self._outer_step(val_task_batch, train=False)\n                    )\n                    losses.append(outer_loss.item())\n                    accuracies_pre_adapt_support.append(accuracies_support[0])\n                    accuracies_post_adapt_support.append(\n                        accuracies_support[-1])\n                    \n                    accuracies_post_adapt_query.append(accuracy_query)\n                loss = np.mean(losses)\n                \n                accuracy_pre_adapt_support = np.mean(\n                    accuracies_pre_adapt_support\n                )\n                accuracy_post_adapt_support = np.mean(\n                    accuracies_post_adapt_support\n                )\n                accuracy_post_adapt_query = np.mean(\n                    accuracies_post_adapt_query\n                )\n\n                print(\n                    f'Validation: '\n                    f'loss: {loss:.3f}, '\n                    f'pre-adaptation support accuracy: '\n                    f'{accuracy_pre_adapt_support:.3f}, '\n                    f'post-adaptation support accuracy: '\n                    f'{accuracy_post_adapt_support:.3f}, '\n                    f'post-adaptation query accuracy: '\n                    f'{accuracy_post_adapt_query:.3f}'\n                )\n                \n                writer.add_scalar('loss/val', loss, i_step)\n                writer.add_scalar(\n                    'val_accuracy/pre_adapt_support',\n                    accuracy_pre_adapt_support,\n                    i_step\n                )\n                writer.add_scalar(\n                    'val_accuracy/post_adapt_support',\n                    accuracy_post_adapt_support,\n                    i_step\n                )\n                writer.add_scalar(\n                    'val_accuracy/post_adapt_query',\n                    accuracy_post_adapt_query,\n                    i_step\n                )\n\n            if i_step % SAVE_INTERVAL == 0:\n                self._save(i_step)\n\n    def test(self, dataloader_test):\n        \"\"\"Evaluate the MAML on test tasks.\n\n        Args:\n            dataloader_test (DataLoader): loader for test tasks\n        \"\"\"\n        accuracies = []\n        for task_batch in dataloader_test:\n            _, _, accuracy_query = self._outer_step(task_batch, train=False)\n            accuracies.append(accuracy_query)\n        mean = np.mean(accuracies)\n        std = np.std(accuracies)\n        mean_95_confidence_interval = 1.96 * std / np.sqrt(NUM_TEST_TASKS)\n        print(\n            f'Accuracy over {NUM_TEST_TASKS} test tasks: '\n            f'mean {mean:.3f}, '\n            f'95% confidence interval {mean_95_confidence_interval:.3f}'\n        )\n\n    def load(self, checkpoint_step):\n        \"\"\"Loads a checkpoint.\n\n        Args:\n            checkpoint_step (int): iteration of checkpoint to load\n\n        Raises:\n            ValueError: if checkpoint for checkpoint_step is not found\n        \"\"\"\n        target_path = (\n            f'{os.path.join(self._log_dir, \"state\")}'\n            f'{checkpoint_step}.pt'\n        )\n        if os.path.isfile(target_path):\n            state = torch.load(target_path)\n            self._meta_parameters = state['meta_parameters']\n            self._inner_lrs = state['inner_lrs']\n            self._optimizer.load_state_dict(state['optimizer_state_dict'])\n            self._start_train_step = checkpoint_step + 1\n            print(f'Loaded checkpoint iteration {checkpoint_step}.')\n        else:\n            raise ValueError(\n                f'No checkpoint for iteration {checkpoint_step} found.'\n            )\n\n    def _save(self, checkpoint_step):\n        \"\"\"Saves parameters and optimizer state_dict as a checkpoint.\n\n        Args:\n            checkpoint_step (int): iteration to label checkpoint with\n        \"\"\"\n        optimizer_state_dict = self._optimizer.state_dict()\n        torch.save(\n            dict(meta_parameters=self._meta_parameters,\n                 inner_lrs=self._inner_lrs,\n                 optimizer_state_dict=optimizer_state_dict),\n            f'{os.path.join(self._log_dir, \"state\")}{checkpoint_step}.pt'\n        )\n        print('Saved checkpoint.')\n\n\ndef main(args):\n    log_dir = args.log_dir\n    if log_dir is None:\n        log_dir = f'./logs/maml/omniglot.way:{args.num_way}.support:{args.num_support}.query:{args.num_query}.inner_steps:{args.num_inner_steps}.inner_lr:{args.inner_lr}.learn_inner_lrs:{args.learn_inner_lrs}.outer_lr:{args.outer_lr}.batch_size:{args.batch_size}'  # pylint: disable=line-too-long\n    print(f'log_dir: {log_dir}')\n    writer = tensorboard.SummaryWriter(log_dir=log_dir)\n\n    maml = MAML(\n        args.num_way,\n        args.num_inner_steps,\n        args.inner_lr,\n        args.learn_inner_lrs,\n        args.outer_lr,\n        log_dir\n    )\n\n    if args.checkpoint_step > -1:\n        maml.load(args.checkpoint_step)\n    else:\n        print('Checkpoint loading skipped.')\n\n    if not args.test:\n        num_training_tasks = args.batch_size * (args.num_train_iterations -\n                                                args.checkpoint_step - 1)\n        print(\n            f'Training on {num_training_tasks} tasks with composition: '\n            f'num_way={args.num_way}, '\n            f'num_support={args.num_support}, '\n            f'num_query={args.num_query}'\n        )\n        dataloader_train = get_omniglot_dataloader(\n            'train',\n            args.batch_size,\n            args.num_way,\n            args.num_support,\n            args.num_query,\n            num_training_tasks\n        )\n\n        dataloader_val = get_omniglot_dataloader(\n            'val',\n            args.batch_size,\n            args.num_way,\n            args.num_support,\n            args.num_query,\n            args.batch_size * 4\n        )\n\n        maml.train(\n            dataloader_train,\n            dataloader_val,\n            writer\n        )\n\n    else:\n        print(\n            f'Testing on tasks with composition '\n            f'num_way={args.num_way}, '\n            f'num_support={args.num_support}, '\n            f'num_query={args.num_query}'\n        )\n        dataloader_test = get_omniglot_dataloader(\n            'test',\n            1,\n            args.num_way,\n            args.num_support,\n            args.num_query,\n            NUM_TEST_TASKS\n        )\n        maml.test(dataloader_test)","metadata":{"id":"7MWfu-UyhWjn","execution":{"iopub.status.busy":"2023-11-11T15:03:15.442944Z","iopub.execute_input":"2023-11-11T15:03:15.443253Z","iopub.status.idle":"2023-11-11T15:03:15.495658Z","shell.execute_reply.started":"2023-11-11T15:03:15.443228Z","shell.execute_reply":"2023-11-11T15:03:15.494734Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Args:\n  def __init__(self):\n    self.log_dir = None\n    self.num_way = 5\n    self.num_support = 1\n    self.num_query = 15\n    self.num_inner_steps = 10\n    self.inner_lr = 0.4\n    self.learn_inner_lrs = False\n    self.outer_lr = 0.1\n    self.batch_size = 16\n    self.num_train_iterations = 15_000\n    self.test = False\n    self.checkpoint_step = -1","metadata":{"id":"I0ZQHYpnuyEF","execution":{"iopub.status.busy":"2023-11-11T15:33:20.748785Z","iopub.execute_input":"2023-11-11T15:33:20.749590Z","iopub.status.idle":"2023-11-11T15:33:20.755758Z","shell.execute_reply.started":"2023-11-11T15:33:20.749558Z","shell.execute_reply":"2023-11-11T15:33:20.754781Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"args = Args()","metadata":{"id":"rK0a9Qycux5L","execution":{"iopub.status.busy":"2023-11-11T15:33:21.018084Z","iopub.execute_input":"2023-11-11T15:33:21.018881Z","iopub.status.idle":"2023-11-11T15:33:21.022958Z","shell.execute_reply.started":"2023-11-11T15:33:21.018851Z","shell.execute_reply":"2023-11-11T15:33:21.022018Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"main(args)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdSwM-b-wcvn","outputId":"d7bd63ba-d58b-4616-ae34-2f0373afef64","execution":{"iopub.status.busy":"2023-11-11T15:33:21.478599Z","iopub.execute_input":"2023-11-11T15:33:21.479272Z","iopub.status.idle":"2023-11-11T15:57:29.811880Z","shell.execute_reply.started":"2023-11-11T15:33:21.479239Z","shell.execute_reply":"2023-11-11T15:57:29.810447Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"log_dir: ./logs/maml/omniglot.way:5.support:1.query:15.inner_steps:10.inner_lr:0.4.learn_inner_lrs:False.outer_lr:0.1.batch_size:16\nCheckpoint loading skipped.\nTraining on 240000 tasks with composition: num_way=5, num_support=1, num_query=15\nStarting training at iteration 0.\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Iteration 0: loss: 1.608, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.209\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.192\nSaved checkpoint.\nIteration 10: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.275, post-adaptation query accuracy: 0.243\nIteration 20: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.125, post-adaptation query accuracy: 0.153\nIteration 30: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.232\nIteration 40: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.184\nIteration 50: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.223\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.259, post-adaptation query accuracy: 0.222\nIteration 60: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.207\nIteration 70: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.178\nIteration 80: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.247\nIteration 90: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.243\nIteration 100: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.199\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.181, post-adaptation query accuracy: 0.179\nSaved checkpoint.\nIteration 110: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.177\nIteration 120: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.125, post-adaptation query accuracy: 0.178\nIteration 130: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.226\nIteration 140: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.193\nIteration 150: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.194\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.134, post-adaptation query accuracy: 0.163\nIteration 160: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.183\nIteration 170: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.198\nIteration 180: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.253\nIteration 190: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.275, post-adaptation query accuracy: 0.256\nIteration 200: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.198\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.191, post-adaptation query accuracy: 0.186\nSaved checkpoint.\nIteration 210: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.199\nIteration 220: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.173\nIteration 230: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.193\nIteration 240: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.150, post-adaptation query accuracy: 0.182\nIteration 250: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.250, post-adaptation query accuracy: 0.233\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.209, post-adaptation query accuracy: 0.207\nIteration 260: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.203\nIteration 270: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.203\nIteration 280: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.250, post-adaptation query accuracy: 0.213\nIteration 290: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.202\nIteration 300: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.150, post-adaptation query accuracy: 0.205\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.278, post-adaptation query accuracy: 0.240\nSaved checkpoint.\nIteration 310: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.168\nIteration 320: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.141\nIteration 330: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.173\nIteration 340: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.218\nIteration 350: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.141\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.178, post-adaptation query accuracy: 0.198\nIteration 360: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.206\nIteration 370: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.125, post-adaptation query accuracy: 0.197\nIteration 380: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.197\nIteration 390: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.150, post-adaptation query accuracy: 0.146\nIteration 400: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.206\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.202\nSaved checkpoint.\nIteration 410: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.250, post-adaptation query accuracy: 0.235\nIteration 420: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.233\nIteration 430: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.191\nIteration 440: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.207\nIteration 450: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.205\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.206, post-adaptation query accuracy: 0.204\nIteration 460: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.182\nIteration 470: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.253\nIteration 480: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.184\nIteration 490: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.168\nIteration 500: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.179\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.203, post-adaptation query accuracy: 0.185\nSaved checkpoint.\nIteration 510: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.177\nIteration 520: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.163\nIteration 530: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.196\nIteration 540: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.173\nIteration 550: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.113, post-adaptation query accuracy: 0.180\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.187\nIteration 560: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.216\nIteration 570: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.288, post-adaptation query accuracy: 0.256\nIteration 580: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.223\nIteration 590: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.202\nIteration 600: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.125, post-adaptation query accuracy: 0.154\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.203\nSaved checkpoint.\nIteration 610: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.175\nIteration 620: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.125, post-adaptation query accuracy: 0.157\nIteration 630: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.210\nIteration 640: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.189\nIteration 650: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.176\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.206, post-adaptation query accuracy: 0.209\nIteration 660: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.275, post-adaptation query accuracy: 0.224\nIteration 670: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.263, post-adaptation query accuracy: 0.223\nIteration 680: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.220\nIteration 690: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.181\nIteration 700: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.144\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.231, post-adaptation query accuracy: 0.210\nSaved checkpoint.\nIteration 710: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.162\nIteration 720: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.166\nIteration 730: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.163\nIteration 740: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.183\nIteration 750: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.195\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.219, post-adaptation query accuracy: 0.216\nIteration 760: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.163, post-adaptation query accuracy: 0.195\nIteration 770: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.234\nIteration 780: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.204\nIteration 790: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.190\nIteration 800: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.219\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.216, post-adaptation query accuracy: 0.203\nSaved checkpoint.\nIteration 810: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.224\nIteration 820: loss: 1.606, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.218\nIteration 830: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.182\nIteration 840: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.225\nIteration 850: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.251\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.209, post-adaptation query accuracy: 0.207\nIteration 860: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.150, post-adaptation query accuracy: 0.187\nIteration 870: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.237\nIteration 880: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.241\nIteration 890: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.170\nIteration 900: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.198\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.166, post-adaptation query accuracy: 0.188\nSaved checkpoint.\nIteration 910: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.169\nIteration 920: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.243\nIteration 930: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.215\nIteration 940: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.252\nIteration 950: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.220\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.178, post-adaptation query accuracy: 0.206\nIteration 960: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.188, post-adaptation query accuracy: 0.191\nIteration 970: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.150, post-adaptation query accuracy: 0.173\nIteration 980: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.233\nIteration 990: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.199\nIteration 1000: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.242\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.200, post-adaptation query accuracy: 0.190\nSaved checkpoint.\nIteration 1010: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.150, post-adaptation query accuracy: 0.162\nIteration 1020: loss: 1.610, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.138, post-adaptation query accuracy: 0.161\nIteration 1030: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.213, post-adaptation query accuracy: 0.232\nIteration 1040: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.238, post-adaptation query accuracy: 0.213\nIteration 1050: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.175, post-adaptation query accuracy: 0.213\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n/tmp/ipykernel_47/1161140225.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  x = imageio.imread(file_path)\n","output_type":"stream"},{"name":"stdout","text":"Validation: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.191, post-adaptation query accuracy: 0.188\nIteration 1060: loss: 1.609, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.225, post-adaptation query accuracy: 0.209\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 487\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    469\u001b[0m     dataloader_train \u001b[38;5;241m=\u001b[39m get_omniglot_dataloader(\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    471\u001b[0m         args\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m         num_training_tasks\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    478\u001b[0m     dataloader_val \u001b[38;5;241m=\u001b[39m get_omniglot_dataloader(\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    480\u001b[0m         args\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m         args\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m    485\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m     \u001b[43mmaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting on tasks with composition \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_way=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mnum_way\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_support=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mnum_support\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_query=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mnum_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    499\u001b[0m     )\n","Cell \u001b[0;32mIn[15], line 293\u001b[0m, in \u001b[0;36mMAML.train\u001b[0;34m(self, dataloader_train, dataloader_val, writer)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    289\u001b[0m outer_loss, accuracies_support, accuracy_query \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outer_step(task_batch, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    291\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[43mouter_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i_step \u001b[38;5;241m%\u001b[39m LOG_INTERVAL \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"%load_ext tensorboard\n","metadata":{"id":"db8-7i9JwcsA","execution":{"iopub.status.busy":"2023-11-11T16:00:07.778482Z","iopub.execute_input":"2023-11-11T16:00:07.778879Z","iopub.status.idle":"2023-11-11T16:00:07.794940Z","shell.execute_reply.started":"2023-11-11T16:00:07.778849Z","shell.execute_reply":"2023-11-11T16:00:07.794143Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!tensorboard --logdir=\"logs/\"","metadata":{"execution":{"iopub.status.busy":"2023-11-11T16:00:09.288337Z","iopub.execute_input":"2023-11-11T16:00:09.288704Z","iopub.status.idle":"2023-11-11T16:00:31.995488Z","shell.execute_reply.started":"2023-11-11T16:00:09.288675Z","shell.execute_reply":"2023-11-11T16:00:31.994273Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\nNOTE: Using experimental fast data loading logic. To disable, pass\n    \"--load_fast=false\" and report issues on GitHub. More details:\n    https://github.com/tensorflow/tensorboard/issues/4784\n\nServing TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\nTensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n^C\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"nZGCQSz_wcos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Implementation of model-agnostic meta-learning for Omniglot.\"\"\"\n\nimport argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch import autograd  # pylint: disable=unused-import\nfrom torch.utils import tensorboard\n\n\nNUM_INPUT_CHANNELS = 1\nNUM_HIDDEN_CHANNELS = 64\nKERNEL_SIZE = 3\nNUM_CONV_LAYERS = 4\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nSUMMARY_INTERVAL = 10\nSAVE_INTERVAL = 100\nLOG_INTERVAL = 10\nVAL_INTERVAL = LOG_INTERVAL * 5\nNUM_TEST_TASKS = 600\n\n\nclass MAML(tf.keras.Model):\n\n  def __init__(self, dim_input=1, dim_output=1,\n               num_inner_updates=1,\n               inner_update_lr=0.4, num_filters=32, k_shot=5, learn_inner_update_lr=False):\n    super(MAML, self).__init__()\n    self.dim_input = dim_input\n    self.dim_output = dim_output\n    self.inner_update_lr = inner_update_lr\n    self.loss_func = cross_entropy_loss\n    self.dim_hidden = num_filters\n    self.channels = 1\n    self.img_size = int(np.sqrt(self.dim_input/self.channels))\n    self._num_inner_steps = 10\n\n    # outputs_ts[i] and losses_ts_post[i] are the output and loss after i+1 inner gradient updates\n    losses_tr_pre, outputs_tr, losses_ts_post, outputs_ts = [], [], [], []\n    accuracies_tr_pre, accuracies_ts = [], []\n\n    # for each loop in the inner training loop\n    outputs_ts = [[]]*num_inner_updates\n    losses_ts_post = [[]]*num_inner_updates\n    accuracies_ts = [[]]*num_inner_updates\n\n    # Define the weights - these should NOT be directly modified by the\n    # inner training loop\n    tf.random.set_seed(100)\n    self.conv_layers = ConvLayers(self.channels, self.dim_hidden, self.dim_output, self.img_size)\n\n    self.learn_inner_update_lr = learn_inner_update_lr\n\n  def call(self, images, parameters):\n\n    outputs = self.conv_layers(images, parameters)\n    return outputs\n\n  def _inner_loop(self, images, labels, train):   # pylint: disable=unused-argument\n\n    accuracies = []\n\n        # ********************************************************\n        # ******************* YOUR CODE HERE *********************\n        # ********************************************************\n        # TODO: finish implementing this method.\n        # This method computes the inner loop (adaptation) procedure for one\n        # task. It also scores the model along the way.\n        # Make sure to populate accuracies and update parameters.\n        # Use F.cross_entropy to compute classification losses.\n        # Use util.score to compute accuracies.\n\n    weights = self.conv_layers.conv_weights\n\n    # here we are doing \\phi_i = \\theta - inner_lr * grad(\\theta, L, D_{tr})\n    for _ in range(self._num_inner_steps):\n\n      with tf.GradientTape(persistent=True) as tape:\n\n        logits = self.call(images, weights)\n        print(logits)\n        loss = self.loss_func(pred = logits, label=labels)\n\n\n      grads = tape.gradient(loss, list(weights.values()))\n      gradients = dict(zip(weights.keys(), grads))\n\n      if self.learn_inner_update_lr:\n        weights = dict(zip(weights.keys(), [weights[key]-self.inner_update_lr_dict[key][0]*gradients[key] for key in weights.keys()]))\n      else:\n        weights = dict(zip(weights.keys(), [weights[key] - self.inner_update_lr*gradients[key] for key in weights.keys()]))\n\n      acc = accuracy(labels, logits)\n      accuracies.append(acc)\n\n    final_logits = self.call(images, weights)\n    final_acc = accuracy(final_logits, labels)\n    accuracies.append(final_acc)\n\n    return weights, accuracy\n\n","metadata":{"id":"aIsMd4c2g2jh"},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"maml_model = MAML()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaaY_fYug2hJ","outputId":"145e585b-6e7a-4a25-f9d3-20f6c488de0f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"maml_model._inner_loop(tf.zeros((10, 100, 100, 3)), tf.zeros((10)), False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":501},"id":"AuJ2M_M3g2dH","outputId":"bbef0835-1100-4fb4-9c53-fc9da6e45e44"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":"tf.Tensor(\n\n[[nan]\n\n [nan]\n\n [nan]\n\n ...\n\n [nan]\n\n [nan]\n\n [nan]], shape=(300000, 1), dtype=float32)\n"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-ad811100ef12>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-ad6cd1e17809>\u001b[0m in \u001b[0;36m_inner_loop\u001b[0;34m(self, images, labels, train)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1063\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1066\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ReshapeGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m   return [\n\u001b[0;32m--> 806\u001b[0;31m       array_ops.reshape(\n\u001b[0m\u001b[1;32m    807\u001b[0m           _IndexedSlicesToTensorNoWarning(grad), array_ops.shape(op.inputs[0])),\n\u001b[1;32m    808\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5887\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5888\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 3000000 values, but the requested shape has 300000 [Op:Reshape] name: "]}]},{"cell_type":"code","source":"","metadata":{"id":"nbd1lLgAg2ZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Z8XFlW2Xg2WV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"NOtfxU3Lg2QH"},"execution_count":null,"outputs":[]}]}